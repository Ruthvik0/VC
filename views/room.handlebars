<section style="position: relative">
    <video
        style="
            margin-top: 10px;
            margin-left: 10px;
            display: inline;
            z-index: 1;
            object-fit: cover;
        "
        width="320px"
        height="160px"
        id="localStream"
        autoplay
        muted
    ></video>
    <video
        style="
            border: 2px solid red;
            width: 100vw;
            height: 100vh;
            position: absolute;
            top: 0;
            left: 0;
        "
        id="remoteStream"
        autoplay
        muted
    ></video>
</section>
<script src="/socket.io/socket.io.js"></script>
<script type="text/javascript">
    let localVideoElement = document.getElementById("localStream");
    let remoteVideoElement = document.getElementById("remoteStream");

    async function init() {
        try {
             let localStream = await navigator.mediaDevices.getUserMedia({
                audio: true,
                video: true,
            });
            localVideoElement.srcObject = localStream;
            const recorder = new MediaRecorder(stream, { type: "audio/webm" });
               recorder.addEventListener('dataavailable', event => {
                 if (typeof event.data === 'undefined') return;
                   if (event.data.size === 0) return;
                   chunks.push(event.data);
                   socket.emit("audio",{chunks})
                 });
               recorder.addEventListener('stop', () => {
                 chunks = [];
               });
            remoteVideoElement.srcObject = null;
        } catch (error) {
            console.error("Error accessing user media:", error);
        }
    }

    let baseUrl = window.location.origin;
    let socket = io(baseUrl);
    init();

    function speakTranslatedText(text) {
        const utterance = new SpeechSynthesisUtterance();
        utterance.lang = "hi-IN";
        utterance.voice = getVoiceForLanguage(utterance.lang);
        utterance.text = text;
        speechSynthesis.speak(utterance);
    }

    let recognition = new webkitSpeechRecognition();
    recognition.lang = "en-US";
    recognition.continuous = true;
    recognition.interm = true;

    recognition.onresult = async function (event) {
        let result = event.results[event.results.length - 1];
        let transcript = result[0].transcript;
        console.log(transcript);
        socket.emit("translateQ", {
            text: transcript,
            from: "en",
            to: "hi",
        });

        socket.on("translateA", (data) => {
            console.log(data.transcript);
            speakTranslatedText(data.transcript);
        });
    };

    recognition.onend = function () {
        console.log("Recognition stopped");
        //recognition.start();
    };
    
    function getVoiceForLanguage(language) {
        let voices = speechSynthesis
            .getVoices()
            .filter((v) => v.lang === language);
        return voices.length > 0 ? voices[0] : null;
    }
    //recognition.start();
</script>
